\documentclass{sigplanconf}

% Email drafts to: M. George Hansen, Evan Laforge

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{balance}

\include{paper}
%include paper.fmt
%format (List (a) (b)) = "[" b "]_{" a "}"
%format Result_alpha = "\Varid{Result_\alpha}"
%format *> = "\mathbin{*\!\!\!>}"
%format **> = "\mathbin{*\!*\!\!\!>}"
%format ?> = "\mathbin{?\!\!\!>}"
%format =*= = "\mathbin{=\!\!*\!\!=}"
%format `replaceExtension` = "\backtick{replaceExtension}"
%subst string a = "\!\text{\sf ``" a "\char34}\!"
%format context = "\Keyword{context}"
%format dependsS = "\Varid{depends\!^{*}}"


\newcommand{\file}{\textsf}
\newcommand{\prog}{\texttt}
\newcommand{\make}{\prog{make}}

\begin{document}
\conferenceinfo{ICFP'12,} {September 27--29, 2010, Baltimore, Maryland, USA.}
\CopyrightYear{2012}
\copyrightdata{978-1-60558-794-3/10/09}

\preprintfooter{}   % 'preprint' option specified.

\title{Shake -- A Better Make}
% \subtitle{}

\authorinfo{Neil Mitchell}
           {\verb"ndmitchell@gmail.com"}

\authorinfo{Max Bolingbroke}
           {\verb"ndmitchell@gmail.com"}

\maketitle

\begin{comment}
1. State the problem
2. Say why it’s an interesting problem
3. Say what your solution achieves
4. Say what follows from your solution
\end{comment}

\begin{abstract}
Build tools, such as \make{}, are typically used for compiling source code into executables. Unfortunately, most build tools fail to properly deal with generated source files, especially when the dependencies of those generated files can only be determined after the files have been generated. In many large software systems generated files are common, resulting in awkward hacks to paper over build tool inadequacies. We describe how to generalise build tools to deal properly with generated files. We have implemented our ideas as the Haskell library Shake, which has been used by Standard Chartered for the last three years as the basis for a complex build system involving millions of lines of code in many languages.
\end{abstract}

\category{D.3}{Software}{Programming Languages}

\terms
Languages

\keywords
build-system, compilation, Haskell

\section{Introduction}
\label{sec:introduction}

A build tool, such as \make{}, takes a set of input files, plus some rules, and produces some output files. Taking \make{} as an example, a build rule looks like:

\begin{code}
{-"\textsf{result.tar : a.txt b.txt}"-}
    {-"\textsf{tar -cf result.tar a.txt b.txt}"-}
\end{code}

\noindent This rule builds the tar archive \file{result.tar} from the inputs \file{a.txt} and \file{b.txt}. Whenever \file{a.txt} or \file{b.txt} changes \file{result.tar} will be regenerated.

What if we want to build \file{result.tar} from the list of files in \file{list.txt}? \make{} offers no easy way to express this pattern (there are workarounds, discussed in \S\ref{sec:make_hacks}, but none are pleasant or effective). However, using the build tool we develop in this paper, we can write:

\begin{code}
"result.tar" *> \_ -> do
    need ["list.txt"]
    contents <- readFileLines "list.txt"
    need contents
    system $ ["tar","-cf","result.tar"] ++ contents
\end{code}

This rule describes how to build \file{result.tar}. We depend on (|need|) the file \file{list.txt}. We read \file{list.txt}, and store each line in |contents| -- which is a list of the files that should go into \file{result.tar}. Next, we depend on all the files in |contents|, and finally call the \prog{tar} program specifying the files in |contents|. If \file{list.txt} changes, or any of the files listed by \file{list.txt} change, then \file{result.tar} will be rebuilt.

The key difference from \make{} (and nearly all other build tools) is that rather than specifying the dependencies of a rule \textit{in advance}, we allow further dependencies to be specified \textit{after} using previous dependencies. This difference is crucial to properly handle generated files.

We have implemented our build tool as a Haskell library, named Shake, which is available online\footnote{\url{http://hackage.haskell.org/package/shake}}. Shake properly handles generated files and includes the important features of \make{}, such as minimal rebuilds (running only a subset of the rules when some subset of the inputs change), and parallelising the build (running multiple independent rules at the same time). By implementing Shake as a Haskell library we allow rules to be written using the full power of Haskell, including the use of modules and functions to properly structure large systems.

\subsection{Contributions}

\begin{itemize}
\item We describe the theory underlying \make{} (\S\ref{sec:theory_make}), and how to revise this theory to properly handle generated files (\S\ref{sec:theory_shake}).
\item We describe how to extend our theory with a cache, to enable minimal rebuilds (\S\ref{sec:theory_shake_cache}).
\item We describe how to implement our build tool in Haskell, including how to present the underlying theory in a way that is practically usable (\S\ref{sec:user_view}), and how to implement it efficiently (\S\ref{sec:developer_view}). While Haskell is not essential to implement our build tool, it offers a number of advantages -- primarily making IO effects explicit and providing nice syntactic sugar.
\item We describe how additional features can be added to our build tool, including a Lint tool (\S?), a profiling tool (\S?) and a dependency analysis tool (\S?).
\item We allow rule dependencies and targets to be arbitrary values. While we can represent files (\S?), we are also able to represent static configuration information (\S?), the list of files in a directory (\S?) and commands that produce multiple results (\S?).
\item We have implemented a large build system using Shake (\S?). The build system is 9000 of lines of Haskell, building over a million lines of source code and over a million lines of generated code, written in many programming languages. We originally implemented this build system using \make{}, but the result was slow to run, hard to maintain, and frequently caused spurious compile failures. Since using Shake, our build system has ceased to be a problem.
\item We give a number of guidelines to follow when using Shake, based on our experiences (\S?).
\end{itemize}


\section{Theory}
\label{sec:theory}

In this section we describe the theory that underpins of \make{}, then the underlying theory of our build system, named Shake. We then describe how to support minimal rebuilds in both theories. In \S\ref{sec:user_view} and \S\ref{sec:developer_view} we show how to implement these ideas in a usable tool.

\subsection{Theory of Make}
\label{sec:theory_make}

While the \make{} tool is heavily file based, that is not an essential property of the ideas behind \make{}. We use the type |Key| for things that can be created or are dependencies (i.e. file names) and the type |Value| for the values associated with a |Key| (i.e.  file contents). Using this abstraction, we can model \make{} as:

\begin{code}
data Rule =
    {creates  :: Key
    ,depends  :: List alpha Key
    ,action   :: List alpha Value -> Value
    }

make :: Set Rule -> Key -> Value
\end{code}

The |make| function takes a (possibly infinite) set of rules and the target |Key| to build, and returns the |Value| associated with that |Key|. A rule can be modelled as the |Key| it |creates|, the |Key|s it |depends| on, and the |action| that takes the depended upon |Value|s and produces the result |Value|. We use |List alpha bullet| to denote a list which must have length |alpha|, requiring that the |depends| list and the list passed to |action| are equal in length.

We restrict our model to only building one target, while \make{} allows multiple targets (i.e. a list of |Key|s to build). However, we can encode multiple targets by creating a distinguished rule that depends on all the targets and returns all their values, and then make that rule the single target.

\subsubsection{Correctness}

We say a |Rule| is associated with a |Key| if it has that |Key| as its |creates| field. Given a |Rule| |r| we can define |dependsS r| as all the |Key|s this rule requires to run, including the dependencies of its dependencies. We can compute |dependsS r| as the union of |depends r| and |dependsS| on all the rules associated to |depends r|.

For a call to |make| to be valid, given a set of rules and a target, we require:

\begin{enumerate}
\item \textit{No duplicate rules} - no |Key| may have two associated rules.
\item \textit{No missing rules} - every item in a |depends| list must have an associated rule.
\item \textit{Target rule} - there must be a rule associated with the target.
\item \textit{Finite} - for all rules, |dependsS r| must be finite.
\item \textit{Acyclic} - for all rules, |dependsS r| must not contain |creates r|.
\end{enumerate}

\noindent Given a valid call to |make|, there exists a finite list of |action|s that when run in order produces the result. Provided each |action| terminates, the result can be obtained.

\subsection{Theory of Shake}
\label{sec:theory_shake}

Using the same terminology from the previous section, we can model our build tool as:

\begin{code}
data Rule =
    {creates  :: Key
    ,action   :: Action
    }

data Action  =  Depends Key (Value -> Action)
             |  Result Value

shake :: Set Rule -> Key -> Value
\end{code}

The |shake| function takes a (possibly infinite) set of rules and the target |Key| to build, and returns the |Value| associated with that |Key|. A rule can be modelled as the |Key| it |creates|, and the |action| that creates the result. The |Action| either returns the |Result| |Value|, or requires a new dependency with |Depends| -- specifying the |Key| it depends on, plus a function that takes the |Value| of that |Key| and provides a new |Action|.

The big difference from |make| is the introduction of dynamic dependencies. A rule can dynamically, based on the values of previous dependencies, require additional dependencies. We can easily translate a |make| |Rule| to a |shake| |Rule|, but the reverse is not true -- |shake| is strictly more powerful than |make|.

\subsubsection{Correctness}

A call to |shake| is correct if the |Value| associated with the target |Key| can be built. Unlike |make|, we cannot check this property before running any |action|s, since new dependencies can be added by running an |action|. Like |make|, we require that each |Key| is associated with exactly one |Rule|. Given a function which finds the rule associated with a key (|find|), we can run a build system as:

\begin{code}
shake rules target = fromKey target
    where
        fromKey k = fromAction (action (find rules k))

        fromAction (Result val) = val
        fromAction (Depends dep act) =
            fromAction (act (fromKey dep))
\end{code}

To reduce a |Key|, we find its |Rule| and reduce its |Action|. To reduce an |Action|, if it is a |Result| we return the value, if it is a |Depends| we reduce the dependency then reduce the result of the action. Note that in this simple implementation every time a |Key| is required we compute its |Value| from scratch -- an action may be run many times.

A call to |shake| is correct if it terminates. We can guarantee termination if:

\begin{enumerate}
\item We require that every |action| function terminates.
\item To ensure that the recursion in |fromAction| terminates, we require that |Rule| produces a finite number of |Depends| constructors before producing a |Result|.
\item To ensure that the recursion in |fromKey| terminates, we require that no |Rule| depends on its |create| value, either directly or through a sequence of other rules.
\item To ensure that the mutual recursion between |fromKey| and |fromAction| terminates, we require that there are a finite number of |Key| values required to build the |target|.
\end{enumerate}

%
% \begin{itemize}
% \item \textit{Result} rules are those whose |action| is a |Result|.
% \item \textit{Reducible} rules are those which are not \textit{results}, but where the immediate dependencies are all \textit{results}.
% \item \textit{Required} rules are those which are not \textit{results}, but which create something in the set of output keys, or who create something that a \textit{required} rule has in it's |Defer| list. We can guarantee that all \textit{required} rules must be evaluated for the build system to finish.
% \end{itemize}
%
% Like in \make{}, the rules |creates| must all be distinct.
%
% Given a set of rules, we are finished when all the \textit{required} rules are \textit{results}. We can proceed one step by taking a rule that is both \textit{required} and \textit{reducible} and running the deferred function on it (\textit{reducing} it). If there are no rules that are both \textit{required} and \textit{reducible} then we are stuck, and the build system has a logical inconsistency, either because there is no rule to build something, or the build rules form a cycle.
%
% Note that we cannot know if the build system is consistent until it has completed. In particular, there are two ways for a build system to loop. Most obviously, an \textit{required} and \textit{reducible} rule could have a deferred action that never terminates. Alternatively, such a rule could immediately produce the same dependencies as previously, without making progress. We assume that each rule is structured in a way that there are a finite number of steps, and each step takes a finite amount of time (in practice, it is hard to write a rule that does not obey this property).
%

\subsection{Minimal Rebuilds in Make}
\label{sec:cached_make}

One of the important properties of \make{} is minimal rebuilds. In any execution of |make|, each |action| will be run at most once. If the last time the action was run it had the same inputs, the action will not be repeated. The \make{} tool uses file modification times, and assumes a target is valid if all its dependencies have older modification times. We can model this behaviour with a function that looks up the modification times:

\begin{code}
history :: Key -> Maybe Value
\end{code}

If we restrict ourselves to |Key|s which are files, and |Value|s which are modification times (as \make{} does), then we can write a function |history| which returns |Just| the modification time, or |Nothing| to indicate the file does not exist (and thus has never been built). An |Rule|s |action| can be skipped if the |creates| file exists, and all the |depends| times are older. Before running a rules action, all its dependencies must already have been created, and thus history must always return |Just|. We can check if a Rule is valid with respect to the history with:

\begin{code}
validHistory :: Rule -> Bool
validHistory r = case history (creates r) of
    Nothing -> False
    Just t -> all ((< t) . fromJust . history) (depends r)
\end{code}

This scheme is limited to files, for two reasons:

\begin{enumerate}
\item Our |history| function relies on being able to access the history for a previous run which is stored on disk. We can eliminate this problem by storing the information in a database as we are executing, and then reloading it from disk on each execution.
\item Our |validHistory| function relies on a |Value| which is monotonically increasing (e.g. time). We can eliminate this problem if whenever we complete an action we give it a real timestamp.
\end{enumerate}

We can make these changes to produce:

\begin{code}
data Info =
    {value :: Value
    ,built :: Time
    }

history :: Key -> Maybe Info

validHistory r = case history (creates r) of
    Nothing -> False
    Just i -> all ((< built i) . built . fromJust . history) (depends r)
\end{code}

However, this scheme is incorrect for |Value|s that are stored by both the file system \textit{and} in our database. Consider a file, which has a file system modification time, and also has a |Value| in our database. If the file is edited externally, then the |Value| in our database will be incorrect. We can solve this problem by also checking that, where the |Value| is stored externally, it is still consistent:

\begin{code}
data Stored = NeverStored | NotStored | Stored Value

stored :: Key -> Stored

validStored :: Key -> Value -> Bool
validStored k v = case stored k of
    NeverStored -> True
    NotStored -> False
    Stored value -> v == value
\end{code}

When attempting to read a value stored externally there are three possible states. Either the value is never stored, in which case it exists only in our database, and is always consistent. Or the value is sometimes stored, but not currently available externally -- such as a file that does not exist on disk, in which case the action must be rerun. Or the value is stored, and has an external value -- in which case the value is valid if it matches what we have stored. We can avoid running the action associated with a rule if it is valid with respect to the stored values, and with respect to the history.

In order to remain consistent throughout the execution, we require that all |stored| values do \textit{not} change during the execution, other than as a result of running an |action| which |creates| it. The \make{} tool requires a similar property or it becomes inconsistent.

While the timestamp approach works reasonably for \make{}, it can fail if the system clock changes, or if a file is modified but has its value set to an older timestamp -- such as when extracting a backup which resets the timestamp. Instead of relying on the system time, we can instead store a counter in our database, and increment it every time we require a time value, thus guaranteeing that our time is correctly ordered.

After running an action, we typically store a new time in the |history|. However, if the result of the |action| has not changed we \textit{do not} update the time. This allows any files that depend on this file to avoid recalculation, which can significantly reduce the number of actions that need to be run.

\subsection{Minimal Rebuilds in Shake}
\label{sec:cached_shake}

Our original algorithm calculated every file repeatedly. We can easily add a cache mapping |Key| to |Value| and avoid reducing a rule that has already been reduced in this execution.

To obtain minimal rebuilds across executions we can use the same approach as described in the previous section. However, we cannot determine whether a |history| is valid based on the rule, as we do not have the |depends| available, and do not want to rerun the |action| just to get the dependencies. Therefore, we just store the dependencies alongside.

\begin{code}
data Info =
    {value :: Value
    ,built :: Time
    ,depends :: [Key]
    }

history :: Key -> Maybe Info

validHistory r = case history (creates r) of
    Nothing -> False
    Just i -> all ((< built i) . built . fromJust . history) (depends i)
\end{code}

We can reuse the |validStored| unmodified.

\subsubsection{Unchanging Files}

Now let us consider the case where a rule runs, but the result is the same as last time. As an example, consider a generated source file. If the generator changes it is necessary to regenerate the file, but there is a chance the result will be the same. In \make{}, the solution is to disallow such changes, and always \prog{touch} the result after a rule completes. However, we can do better, avoiding unnecessary computation.

Instead of storing just the built time, we can also store the |changed| time. Whenever we build a file we update its |built| time, but if the value is the same as last time, we leave its |changed| time the same. When checking |validHistory| we can replace the condition as:

\begin{code}
all ((< built i) . changed . fromJust . history) (dependedUpon i)
\end{code}

By introducing two timestamps for a single |Key|, we can reduce the number of builds required. For certain practical examples, this improvement can reduce rebuild times after a change from many minutes to seconds.

\section{Shake in Haskell}
\label{sec:user_view}

In order to make the theory from \S\ref{sec:theory} practically usable as a Haskell library, we need to make a number of design decisions. In particular, we describe how to replace |Key| and |Value| with standard polymorphic values, how to integrate IO into the |action| function and how to define an infinite set of rules. We first present the interface to Shake, then in \S\ref{sec:developer_view} we describe how to implement the internals of the library.

\subsection{A Shake Example}

\begin{figure}
\begin{code}
import Development.Shake
import System.FilePath

main = shake def $ do
    want ["Main"]

    "Main" *> exe -> do
        cs <- getDirectoryFiles "." "*.c"
        let os = map (`replaceExtension` "o") cs
        need os
        system_ $ ["gcc","-o",exe] ++ os

    "*.o" *> \o -> do
        let c = replaceExtension o "c"
        need [c]
        headers <- liftIO (cIncludes c)
        need headers
        system_ ["gcc","-o",o,"-c",c]
\end{code}
\caption{Demo build system in Shake.}
\label{fig:demo}
\end{figure}

We give an example Shake program in Figure \ref{fig:demo}. Running this program will build \file{Main} from all the \file{*.c} files in the current directory. If we add or remove a \file{.c} file, or change any of the \file{.c} files or the header files they @#include@, then the necessary files will be recompiled.

The script produces (|want|'s) the file \file{Main}. To generate \file{Main} we list all the \file{*.c} files in the current directory, change their extensions to \file{*.o}, require those files to be built (|need| them), then call \prog{gcc} to link them. To build any \file{*.o} file we take the associated \file{*.c}, make sure it's been built, then call the function |cIncludes| to get all headers it includes (|cIncludes| can be defined in terms of \prog{gcc -M}). We require those headers, then we call \prog{gcc} to do the compilation.

This script demonstrates a number of features of Shake based build systems:

\begin{itemize}
\item It's a full Haskell program with a |main| entry point. While |main| can simply call |shake|, it can also do anything it likes, such as command line processing (see \S?).
\item The call to |getDirectoryFiles| is tracked (see \S?), if the results change, it will trigger a rebuild.
\item We run arbitrary system commands in the internals.
\item We fully track the dynamic dependencies introduced by header files. The function |cIncludes| given a source file returns all the files required by transitive @#include@ directives. (In \S? we show a better way to define transitive dependencies.)
\end{itemize}

\subsection{Core Shake}

\begin{figure}
\begin{code}
data ShakeOptions = ShakeOptions
    {shakeFiles :: FilePath
    ,shakeParallel :: Int
    ,ellipses
    }
    deriving (Default)

data Rules a
    deriving (Monad, Monoid)

data Action a
    deriving (Monad, LiftIO)

class (
    Show key, Show value,
    Typeable key, Typeable value,
    Hashable key, Hashable value,
    Eq key, Eq value,
    Binary key, Binary value
    ) => Rule key value | key -> value where
    validStored :: key -> value -> IO Bool
    validStored k v = return True

run :: ShakeOptions -> Rules () -> IO ()

action :: Make a -> Rules ()

rule, defaultRule :: Rule key value =>
    (key -> Maybe (Make value)) -> Rules ()

apply :: Rule key value => List alpha key -> Make (List alpha value)
apply1 :: Rule key value => key -> Make value
\end{code}
\caption{Primitive operations in Shake}
\label{fig:shake_core}
\end{figure}

The primitive interface to Shake is given in Figure \ref{fig:shake_core} -- everything else is defined on top. At its essence, a Shake build system is a set of rules. We can run the rules with |run|, create new rules with |rule|/|defaultRule|/|action|, and when defining a rule we can express a dependency with |apply|/|apply1|.

We execute a set of rules with the |run| function, which also takes an options record. Typical options include which file to store the cached versions in (|shakeFiles|), and the number of processors to use (|shakeParallel|). These options are also used to select which mode to run Shake in, as described in \S\ref{sec:tools}.

Every rule that is defined or applied in Shake must be a member of the |Rule| class. The |Rule| class defines the method |validStored| to determine whether a value is consistent with the value stored externally. We require that each rule |key| has only one type of |value|, this restriction is not technically required, but forces users to keep their rules simple. Each |key|/|value| type must also be in several type classes:

\begin{description}
\item [Typeable] We allow multiple types of rules in a single build system. To distinguish the types, and to match on only one type at a time, we require a |Typeable| constraint.
\item [Eq] We require equality to match the values.
\item [Binary] We require |Binary| so we can store the values in a database, to achieve minimal rebuilds.
\item [Hashable] We require |Hashable| to perform fast searching.
\item [Show] We require |Show| for debugging messages and logging.
\end{description}

Standard Shake rules are defined with |rule|, which requires a function which takes a single |key| value, and returns |Nothing| to indicate that this rule does not build this |key|, or |Just| with the steps necessary to build the associated |value|. If two rules match the same key then an error is raised. The function |defaultRule| allows a rule to be defined with a lower priority, which is used if no standard rules match -- for an example see \S\ref{sec:user_view_files}. Instead of defining targets to build, we allow rules with no target, which are always run. The |Rules| type is a |Monoid|, allowing two sets of rules to be appended to produce a new set of |Rules|. In practice, the syntactic sugar supported by |Monad| is often a more natural way to define rules in a build system, so we also make |Rules| a |Monad|. The |Action| type is a |Monad| and has an instance for |MonadIO|, allowing users to call arbitrary |IO| functions using |liftIO| to translate |IO alpha| to |Action alpha|.

The |apply1| function takes a |key|, builds it, and returns the associated |value|. The |apply1| function finds a rule of the appropriate type whose application returns |Just|, then runs the action. The |apply| function can be thought of as |mapM apply1|, but is defined to build all necessary dependencies in parallel (see \S\ref{sec:parallelism}).

We have deliberately kept the core of Shake small and extensible, supporting all instantiations of |Key|/|Value| outside, thus focusing purely on the building side. We describe how to implement this core in \S\ref{sec:developer_view}.

\subsection{Defining Rule Types}

To work correctly, the |key|/|value| types of |apply1| and |rule| must match each other. To aid end users, we suggest that most rule authors define sugar functions, as we have done for the rule types included with Shake. The simplest rule available is one that determines if a file exists, similar to the standard function |System.Directory.doesFileExist|, but where the dependency is tracked. As an example, consider the following rule:

\begin{code}
".config" *> \dest -> do
    b <- doesFileExist ".config.user"
    let src = if b then ".config.user" else ".config.default"
    copyFile src dest
\end{code}

This rule creates \file{.config} by copying either \file{.config.user} if it exists, or otherwise copying \file{.config.default}. The intention is that there is a default configuration, but it can be overridden by then user. Note the use of dynamic dependencies -- if the user has a \file{.config.user}, and the \file{.config.default} changes then the rule will not be run, however if the file didn't exist it would be.

\begin{figure}
\begin{code}
import System.Directory as IO

newtype Exist = Exist FilePath
-- plus instances for |Typeable|, |Show|, |Eq|, |Hashable| and |Binary|

instance Rule Exist Bool where
    validStored (Exist x) b = liftM (== b) $ IO.doesFileExist x

doesFileExist :: FilePath -> Action Bool
doesFileExist = apply1 . Exist

defaultRuleDoesFileExist :: Rules ()
defaultRuleDoesFileExist =
    defaultRule $ \(Exist x) -> Just $
        liftIO $ IO.doesFileExist x
\end{code}
\caption{Implementation of |doesFileExist|.}
\label{fig:doesfileexist}
\end{figure}

We define |doesFileExist| in Figure \ref{fig:doesfileexist}. We first define a |newtype| wrapper to represent the |key| type, deriving all the necessary classes. We define an instance for |Rule Exist Bool|, where |validStored| simply checks that the existence of the file matches. We define |doesFileExist| as very gentle sugar around |apply1|, the primary purpose is to tie down the types, so users cannot make mistakes. Finally we define a |defaultRule| which runs the action. Anyone wishing to use |doesFileExist| should include |defaultRuleDoesFileExist| in their rule set.

We use a restricted module export list to export only |doesFileExist| and |defaultRuleDoesFileExist|, and thus we are guaranteed that the types match. Note that if a value changes we are likely to call |IO.doesFileExist| twice in a row, once to invalidate the old value in |validStored|, and once to compute the new value in |default_|. We can alleviate this problem with a single element cache -- although in practice we find it not to be a problem, since the operating system typically caches all file queries.

We end with a note of caution. We require that any stored value remains consistent other than when a rule actively changes in. Since this rule does not force the existence of a file, it should not be used on any files that may be generated by the build system -- |doesFileExist| should return the same at the start and end of the compilation.

\subsection{File Based Rules}

\begin{figure}
\begin{code}
import System.Directory as IO

newtype File = File FilePath
newtype FileTime = FileTime Int
-- plus all necessary instances

getFileTime :: FilePath -> IO (Maybe FileTime)
getFileTime x = do
    b <- IO.doesFileExist x
    if not b then return Nothing else do
        TOD t _ <- IO.getModificationTime x
        return $ Just $ FileTime $ fromIntegral t

instance Rule File FileTime where
    validStored (File x) t = fmap (== Just t) $ getFileTime x

need :: [FilePath] -> Action ()
need xs = (apply $ map File xs :: Action [FileTime]) >> return ()

defaultRuleFile :: Rules ()
defaultRuleFile = defaultRule $ \(File x) -> Just $ do
    res <- liftIO $ getFileTime x
    let msg = "Error, file does not exist and no available rule: " ++ x
    return $ fromMaybe (error msg) res

want :: [FilePath] -> Rules ()
want xs = action $ need xs

(?>) :: (FilePath -> Bool) -> (FilePath -> Action ()) -> Rules ()
(?>) test act = rule $ \(File x) ->
    if not $ test x then Nothing else Just $ do
        liftIO $ createDirectoryIfMissing True $ takeDirectory x
        act x
        res <- liftIO $ getFileTime x
        let msg = "Error, rule failed to build the file: " ++ x
        return $ fromMaybe (error msg) res

(**>) :: [FilePattern] -> (FilePath -> Action ()) -> Rules ()
(**>) test act = (\x -> any (x =*=) test) ?> act

(*>) :: FilePattern -> (FilePath -> Action ()) -> Rules ()
(*>) test act = (test =*=) ?> act
\end{code}
\caption{Implement of file rules.}
\label{fig:file_rules}
\end{figure}

While our build system is not restricted to rules dealing with files, in practice many build systems are file orientated. For files, the filename is a sensible |Key|, but |Value| could be either the on-disk modification time or a hash of the file contents (e.g. SHA1). We found in that modification time is faster (significantly faster for large files) and being able to rebuild something with \prog{touch} is highly convenient! Of course, our design allows anyone to define a new file type, based on file hashes. Using modification time for values, we define the functions for working with files in Figure \ref{fig:file_rules}.

To force files to be built, we define |need| and |want|. The |need| action demands all the modification times associated with the filenames, then throws away the result -- a computation depends on the time a file was built, but rarely uses the modification time in its computation. We define |want| as simply a |need| run as an action.

We define |defaultRuleFile| as a rule that simply checks if the file is already present, and if so uses it. Source files will have no associated rules, so this rule just records their modification time. If a file has no rules (since any rules would be run in preference to the default rule), and does not exist, then we give an error to the user. As with |defaultRuleDoesFileExist|, anyone using |want|/|need| should include |defaultRuleFile| in their rule set.

We define new file rules with |(?>)|, which takes a predicate to match against the file name and an action to run. This function forces the correct types, and obtains the modification time afterwards. Before running the action we create the directory containing the output file, an idea taken from the Ninja build system \cite{ninja}. We found that when running a large set of newly written rules, often one rule would create the output directory while another did not -- meaning some rule orderings worked while others failed. Automatically creating the output directory removes this source of failure.

While |(?>)| is the ultimate file creation rule, we define two additional operators, in terms of a wildcard match operator |(=*=)|. We define |(*>)| for matching a single pattern, for example |"*.c" *> ellipses|, in a very similar manner to \make{}. We also define |(**>)| for matching any one of a set of patterns. In our large evaluation, we found that |(?>)| was used about 5\% of the time, |(**>)| was used about 10\% and |(*>)| was used about 85\% of the time. In our experience, use of |(?>)| is a sign that the build system is poorly designed and should be rethought (our large evaluation used |(?>)| exclusively for compatibility with the system it replaced).

\subsection{Derived Operations}

Using the file rules from the previous section, we can define new versions of operations such as |readFile|, which automatically call |need|:

\begin{code}
readFile :: FilePath -> Action String
readFile x = need [x] >> liftIO (IO.readFile x)
\end{code}

We also define a number of helpful utilities:

\begin{itemize}
\item |readFileLines| reads a file and splits the result into lines.
\item |writeFile|/|writeFileLines| just use |liftIO| to lift the |writeFile| call into the |Action| monad.
\item |system| takes a list of command line arguments and escapes them as necessary. It's also useful for profiling (see \S\ref{sec:profiling}. Note that |system| does not automatically know, so must be used carefully.
\end{itemize}

We can also hoist |need| calls.


We can layer on sugar like |readFileLines| quite easily. And also |readFile|, |system|, |mkdir|. In all cases, we try and emulate the \make{} behaviour of being more relaxed.

\begin{code}
readFile_ :: FilePath -> Make String
readFile_ x = do
    need x
    liftIO $ Prelude.readFile x

system :: [String] -> Make ()
system xs = do
    x <- System.system $ unwords xs
    unless (x == ExitSuccess) $ error "Failed when running command"

mkdir :: FilePath -> Make ()
mkdir x = liftIO $ createDirectoryRecursive True x

cp :: FilePath -> FilePath -> Make ()
cp src dest = do
    need [src]
    liftIO $ copyFile src dest
\end{code}

\subsection{Wrapping}

We can then defined:

\begin{code}
shake opts rules = run opts $ do
    fileRule
    lsRule
    rules
\end{code}

Note that if we had |defaultRule| in the type class, we could avoid having the |shake| wrapper.

\section{Implementing Shake}
\label{sec:developer_view}

We can implement Shake relatively easy. We don't give the entire implementation (for that, download the package from Hackage), but sketch some of the central ideas. When implementing Shake there are several goals:

\begin{description}
\item[Correctness] -- always rebuild enough, but we never rebuild something that could be reused.
\item[Efficiency] -- we try and make the implementation efficient.
\item[Parallelism] -- we try and do as much in parallel as possible.
\item[Error feedback] -- if the build system fails for some reason, such as the rules being incorrect as per \S\ref{sec:theory_shake}, then it's nice to give useful error messages. While this may sometimes conflict with efficiency (maintaining extra state to only be used in an error), it makes the system practical.
\end{description}

We first describe an implementation that is capable of building simple rules without parallelism of caching. We then add caching, and finally add parallelism.

Throughout this work, we assume that the build script does not change, merely the inputs. We make some allowances and checks for this case, but generally if you change the build script you should wipe the build.

\subsection{Dynamically Typed Values}
\label{sec:dynamically_typed}

Shake can work with multiple types of value in the rules. Storing heterogenous values in Haskell is problematic, so we define:

\begin{code}
data Any = Any (forall a . C a => a)
    deriving (Eq, Ord, Hashable, Binary)

type Key = Any
type Value = Any
\end{code}

This is a way of abstracting the |Key| and |Value| to store anything. For |Eq| and |Ord| and |Hashable| we just use the |TypeRep| and value as a pair, and apply the methods as that would be appropriate.

Defining the Binary instance is far harder. Serialising a value is easy, but deserialising a value is a nightmare -- we need to figure out the type of the value so we can find it's |Binary| instance. We solve this problem by building a table of all instances we know about which are referred to by |rule|. If there are no rules to build something it isn't useful, so we use that table to index in. Since storing the full type would require storing lots of types, we instead index them into a table and have a lookup table by index. While these concerns are fiddly and low-level, they can largely be ignored and we can assume all |Any| values have a good |Binary| instance. When deserialising, if we encounter a binary instance that we don't have a copy of, we just ignore the entire cache. This is pessimistic, but safe -- if the set of types has changed that implies the build system has changed, which is not tracked anyway (see \S\ref{sec:changing_makefile}).

\subsection{Basic Implementation}

Note that \make{} builds a graph, we can't do that. However, given the nature of the problem, we highly doubt that implementing \make{} by building a graph is the right approach! If we ignore parallelism and caching, we can build using a variable of the following type:

\begin{code}
type State = Map Key Status

data Status  =  Building
             |  Built Value
\end{code}

At every point we have a global |State| value, initially starting with an empty |Map|. When we try and build an action we add it to the |State| as |Building|. When we have built all it's dependencies, and run it, we add it to the |State| as |Built|. If while running the build system we encounter a |Building|, then we have a cycle where a |Key| depends on itself.

When building a rule that has multiple outputs we always store it by the minimum |Key| value, which makes it consistent. Anything else that is done is put on the map with an |Also| pointing at the original key.

Our TimeStamp can just be the number of runs, which means we can use a 32bit Int with no practical chance of overflowing. If values are equal then that is still safe.

\subsubsection{Adding a Cache}
\label{sec:theory_shake_cache}

The standard behaviour for Shake is then to add a cache to get minimal rebuilding. Given a set of Key/Value pairs from last time, and a history trace.

We add code to save |Key|/|Value|, which is a pain with the existential, but possible.

Before running a rule, if we have something with an equal key

\begin{code}
data Status  =  Building
             |  Built   Time Value [Key]
             |  Loaded  Time Value [Key]
\end{code}

When you compute something, if it existed and had the same version, and is identical, keep the same number. You are dirty if the version numbers of your keys do not match your version number. This allows multiple rebuilds to work properly. Also have a cache which means you and all your children have up to date versions. Do not save that boolean.

Version numbers let you load all the cache, validate and potentially rebuild some portion of the known universe, then save the cache back. As a result, some parts of the cache may have a much higher version than others, but you don't need to kill the rest until it gets broken. In any one run, a version number may only increase once at the same time as it gets its cached bit set to True.

Important point: if you run something, and it's dependencies are dirty, but it gave the same answer, you can still use that in the cache.



The reason for |[[Key]]| instead of just |[Key]| is so we figure out what can be checked in parallel.

For each Key/Value pair we also store the Key/Value list that was accessed during that run. We can do this quite effectively:

\begin{code}
-- Make sure key is in the cache, and has either has Equal or Different state.

ask :: Value ->

ask key =
    if Doing then error "has a loop"
    if Equal || Different then done
    if Unchecked then
        for each key
            ensures x
            if any are not equal then bail to Missing
    if Missing then
        run rule

ensures
\end{code}

rule = if has a value in the history, then need all the keys from last time. If they are all currently equal to their historic values then move from history to current. Work by maintaining two dictionaries

We also practically use a journal, so that hitting Ctrl+C doesn't break it. Do we need to remember if things are different/same when storing the cache?

\subsubsection{Parallelism}

Just add a lock in the Doing, use a thread pool and you are done. We always fork off all the rules in parallel, and modify the table atomically, but when checking equality we only fork threads if there is something to do (otherwise you end up with a lot of very small actions - since most just compare equalities).

\begin{code}
data Status
    = Building Lock
    | Built   Time Value [[Key]]
    | Loaded  Time Value [[Key]]
\end{code}

We can optimise by running the check in parallel, and we also need to put a global lock around the map. We need to store the keys as a list so that when we have to rebuild N keys that have changed we can ensure they are done in parallel too.

We also need to implement a journal, important for killed builds. The journal is idempotent.

\subsection{Error Messages}

We track the stack, so on errors when can show it nicely. We also have a @--verbose@ option to show all system commands called. These are seriously helpful for debugging. Also, all calls to |system| are wrapped and throw an error including their command line.

\subsection{Cleaning}

A standard feature of build systems is cleaning operations. We can rebuild everything by just deleting the cache. Also note that the cache may have garbage in -- things which are old, stale, and not useful. However, we don't make any attempt to delete them -- in practice wiping a rebuilding is sufficiently common. However, we could say that anything which has not been used gets cleared.

\section{User Tools}
\label{sec:tools}

\subsection{Profiling}

We record trace information and build duration. We can then create a rich analysis toolbox.

\subsection{Analysis}

We have dependency information.

\subsection{Lint checking}

\section{Evaluation}
\label{sec:evaluation}

We have used the resulting system extensively. It replaced a huge and error prone build system. Cite the 15\% study, and say we do very little.

\begin{code}

hasFlag :: String -> Bool

dotNet = do
    ruleAlways $ do
        res <- run1 $ Flag "DOTNETGEN"
        when res $
            addins <- run1 Addins
            need [dist $ x <.> "dll" | x <- addins]
\end{code}

Typically a system checks 360,000 files in a run.

Depths of files are:

[(0,2127),(1,22651),(2,190623),(3,64795),(4,15666),(5,22732),(6,10583),(7,11801),(8,5658),(9,5035),(10,3144),(11,2500),(12,974),(13,605),(14,251),(15,230),(16,73),(17,25),(18,25),(19,6),(20,1)]

\subsection{Multiple Outputs}

GHC produces a .hi and a .o file. You can think of the .o file as depending on the entire contents of the file, and the .hi depending on only the type signatures. A single GHC invocation needs to do all the work to do both, but often it won't change the .hi file if it doesn't need to. The multiple results captures this perfectly.

In most cases you can fake the dependency - i.e. say that Foo.o depends on both Foo.hs and Foo.hi - which may work, as whenever one gets built the other will be. However, consider a process that reads a file and splits it into the even numbers and the odd numbers, avoiding writing the file back if nothing has changed.

Sometimes running one command will produce two outputs. As an example, running \prog{ghc} on \file{Foo.hs} produces both \file{Foo.o} and \file{Foo.hi}. Some things (things importing \file{Foo.hs}) require \file{Foo.hi}. Some things, say linking, require \file{Foo.o}. We can fake this because we know that a change in the \file{*.o} timestamp changes the \file{*.hi} timestamp, so we can write:

\begin{code}
"*.hi" *> \hi ->
    need [replaceExtension hi "o"]

"*.o" *> \o ->
    let hs = replaceExtension x "hs"
    need [hs] -- and it's dependencies, but let's ignore that for now
    system ["ghc","-c",hs]
\end{code}

Note that if we wrote it the other way, with the \file{*.o} depending on the \file{*.hi} then if the \file{*.hi} stayed the same we could end up screwed. We'd have written that neither file had changed, but both would have. Ouch. Also if we use SHA1 it's now not correct.

We can work around the problem by introducing a new type, |File2| which stores two files. We can then ask for both files at once, which computes them and stores both timestamps. Now to compute either we depend on the Both rule, and since that always changes when either does, we're safe.

\subsection{Transitive Dependencies}

We can define the implementation as... this only does one layer.

We can also define a more specific one, based on the assumption that @#ifdef@ statements do not change the include files (a reasonable assumption in many cases).

If you have a transitive dependency you can avoid it quite easily. Consider the problem of .c/.h include files. We can define a correct implementation as...


\subsection{Rules to Follow}

Put all generated files somewhere entirely separate, such as dist or |_make|. Do not comingle them.

Make sure you normalise all filepaths, we recommend making them all relative to the root, never use combinations of @.@ and @/@ or @\\@.

We also have found that when you use |(?>)| you are probably going too complicated. As an example:

\begin{code}
(\x ->  obj "/Root/*/*.hs" ?== x &&
        not ("Generated" `isInfixOf` x) &&
        not ("Hs" `isPrefixOf` takeFileName x))
    ?> ellipses
\end{code}

This rule seems like a complete hack to me -- these special cases are likely added based on corners that should have been removed.

\subsection{Lots of things generate .o files}

Then change them to have an extra extension, such as .hs.o.

\subsection{Command Line}

Just use actionAllow to filter which things they are allowed to need. You should be very careful not to miss out on things that they actually use, as you'll like get an error.

\subsection{Type Safety}

The |rule|/|apply| functions are checked at runtime. However, since everyone uses sugared versions, that isn't an issue. It should be relatively easy to define a statically typed rule that accumulates its types used, but it's more complex.

\subsection{Comparison to @ghc --make@}

Compared to GHC --make, building the Shake project takes 9 seconds to compile, while GHC --make takes 6 seconds. The reason for the difference is that GHC has to analyse dependencies once, and can keep .hi information in memory. However, Shake can fight back with some parallelism - in the Shake demo, if we scale each compilation to 5seconds, then GHC would take at least 70 seconds, while Shake can gain with parallelism to take 45 seconds. Compared to something like gcc, which is always invoked in single mode, we do better.

However, we do far better for a null rebuild. We have essentially reduced it to a question of which files already exist, and which timestamps do a set of files -- to rebuild GHC must ask at least these questions, and in practice will look at the insides of each file. As a result, we can do a minimal rebuild in 0.03 seconds, while GHC takes 0.6 seconds. Our only unnecesary overhead is reading in the database.

\section{Related Work}
\label{sec:related_work}

Build systems are an essential part of any large software project, yet often prove surprisingly tricky to get right. While most languages have a nice tool for building single language projects (ocamlbuild, ghc --make, Visual Studio projects), when building more complex multi-language projects, most people turn to \make{}. While there are many \make{} competitors (Scons, CMake, Ant), none have gained universal acceptance. We present Shake, a new build system based on a more powerful approach, which can do things \make{} cannot -- handling generated files properly. We have implemented Shake in Haskell, as a Haskell library, and it is used heavily -- compiling 10's of millions of lines of code per day.

A standard build system generates a dependency graph for all files, and processes them to meet the dependency constraints.

Ninja the Chromium build system has dynamic dependencies (you can specify a rule that contains dependencies), multiple outputs. It focus on only running command lines, and is a bit more limited, but still encompasses many of the same ideas.

gittup.org/tup

"redo"

\section{Conclusions}
\label{sec:conclusions}

Shake is awesome. Any future work goes here.

\subsection*{Acknowledgements}

Thanks to Standard Chartered, where the software was developed. Thanks to Raphael Montelatici for the name Shake. Thanks to Evan Laforge for discussions, particularly about multiple files.


\bibliographystyle{plainnat}
\balance
\bibliography

\end{document}
