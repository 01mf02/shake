\documentclass{sigplanconf}

% Email drafts to: M. George Hansen, Evan Laforge

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{balance}

\include{paper}
%include paper.fmt
%format (List (a) (b)) = "[" b "]_{" a "}"
%format Result_alpha = "\Varid{Result_\alpha}"
%format *> = "\mathbin{*\!\!\!>}"
%format ?> = "\mathbin{?\!\!\!>}"
%format ?= = "\mathbin{?\!\!\!=}"
%format `replaceExtension` = "\backtick{replaceExtension}"
%subst string a = "\!\text{\sf ``" a "\char34}\!"
%format context = "\Keyword{context}"


\newcommand{\file}{\textsf}
\newcommand{\prog}{\texttt}
\newcommand{\make}{\prog{make}}

\begin{document}
\conferenceinfo{ICFP'12,} {September 27--29, 2010, Baltimore, Maryland, USA.}
\CopyrightYear{2012}
\copyrightdata{978-1-60558-794-3/10/09}

\preprintfooter{}   % 'preprint' option specified.

\title{Shake -- A Better Make}
% \subtitle{}

\authorinfo{Neil Mitchell}
           {\verb"ndmitchell@gmail.com"}

\authorinfo{Max Bolingbroke}
           {\verb"ndmitchell@gmail.com"}

\maketitle

\begin{comment}
1. State the problem
2. Say why it’s an interesting problem
3. Say what your solution achieves
4. Say what follows from your solution
\end{comment}

\begin{abstract}
Build tools, such as \make{}, are typically used for compiling source code into executables. However, most build tools fail to properly deal with generated source files, especially when the dependencies of the generated files can only be determined after the file has been generated. In many large software systems generated files are common, resulting in awkward hacks to paper over build tool inadequacies. We describe how to generalise build tools to deal properly with generated files. We have implemented our ideas as the Haskell library Shake. Shake has been used by Standard Chartered for the last three years as the basis for a complex build system involving millions of lines of code in many languages.
\end{abstract}

\category{D.3}{Software}{Programming Languages}

\terms
Languages

\keywords
build-system, compilation, Haskell

\section{Introduction}
\label{sec:introduction}

A build tool, such as \make{}, takes a set of input files, plus some rules, and produces some output files. Taking \make{} as an example, a build rule looks like:

\begin{code}
{-"\textsf{result.tar : a.txt b.txt}"-}
    {-"\textsf{tar -cf result.tar a.txt b.txt}"-}
\end{code}

\noindent This rule builds the tar archive file \file{result.tar} from the inputs \file{a.txt} and \file{b.txt}. Whenever \file{a.txt} or \file{b.txt} changes \file{result.tar} will be regenerated.

What if we want to build the file \file{result.tar} from the list of files in \file{result.files}? \make{} offers no easy way to express this pattern (there are workarounds, discussed in \S\ref{sec:make_hacks}, but none are pleasant or effective). However, using the build tool we develop in this paper, we can write:

\begin{code}
"result.tar" *> \_ -> do
    need ["result.files"]
    contents <- readFileLines "result.files"
    need contents
    system $ ["tar","-cf","result.tar"] ++ contents
\end{code}

This rule describes how to build \file{result.tar}. We depend on (|need|) the file \file{result.files}. We read \file{result.files}, and store each line in |contents| -- which is a list of the files that should go into \file{result.tar}. Next, we depend on all the files in |contents|, and finally call the \prog{tar} program specifying the files in |contents|. If the file \file{results.files} changes, or any of the files listed by \file{results.files} change, then \file{result.tar} will be rebuilt.

The key difference from \make{} (and nearly all other build tools) is that rather than specifying the dependencies of a file \textit{in advance}, we allow further dependencies to be specified \textit{after} using previous dependencies. This difference is crucial to properly handle generated files.

In addition, we also deal with multiple things, way more than just files. Even though we now deal with more than files, this helps with rules that depend on static configuration (\S?), directory contents (\S?), rules that generate multiple results (\S?) and other things. The power of multiple types really keeps the core simple.

We have implemented our build tool as a Haskell library, named Shake, which is available online\footnote{\url{http://hackage.haskell.org/package/shake}}. Shake properly handles generated files, as well as the important features of \make{}, such as minimal rebuilds (running only a subset of the rules when some subset of the inputs change), and parallelising the build (running multiple independent rules at the same time). By implementing Shake as a Haskell library we allow build system authors the full power of abstraction, using Haskell features such as modules/functions.

\subsection{Contributions}

\begin{itemize}
\item We describe the theory underlying \make{} (\S\ref{sec:theory_make}), and how to revise this theory to properly handle generated files (\S\ref{sec:theory_shake}).
\item We describe how to extend our theory with a cache, to enable minimal rebuilds (\S\ref{sec:theory_shake_cache}).
\item We describe how to implement our build tool in Haskell, including how to present the underlying theory in a way that is practically usable (\S\ref{sec:user_view}), and how to implement it efficiently (\S\ref{sec:developer_view}). While Haskell is not essential to implement our build tool, it offers a number of advantages -- primarily making IO effects explicit and providing nice syntactic sugar.
\item We describe how additional features can be added to our build tool, taking inspiration from from compilers. We describe how to implement a Lint tool (checking all dependencies are present and the system will perform the same in parallel as in serial), a profiling tool (which rules take most time) and an analysis tool (which input file caused a rule to fire). Many of these features are directly driven by the theory.
\item We have implemented a large build system, building more than a million lines of code, producing lots of objects, multiple languages and thousands of lines of build code. We originally implemented this system in \make{}, but failed, so switched. We compare our build systems, and also give a number of guidelines to follow when using Shake.
\end{itemize}


\section{Theory}
\label{sec:theory}

In this section we first recap roughly how \make{} works, then show how Shake works. We show that \make{} has some theoretical limitations, which we resolve. In \S\ref{sec:user_view} we show how we can implement these ideas in a library.

\subsection{Theory of Make}
\label{sec:theory_make}

We deliberately abstract away the entire idea of files. While \make{} is heavily file based, that is not an intrinsic property of the theory behind \make{}. We use |Key| for things that can be inputs or output (think file names) and |Value| for the value associated with the |Key| (think file contents).

We can model \make{} as:

\begin{code}
data Rule =
    {depends :: List alpha Key
    ,creates :: Key
    ,rule :: List alpha Value -> Value
    }

make :: Set Rule -> List alpha Key -> List alpha Value
make rules xs = ellipses
\end{code}

We can model \make{} as a function that takes a (possibly infinite) set of rules, a list of what we need to build, and builds it. We use |List alpha bullet| to denote a list which must have length |alpha|. In |make|, the number of values generated must correspond to the number of keys passed in (and in fact, each rule must be the result). A rule can be modelled as the things it depends on, the thing it creates, and the rule that takes the depended keys and produces the result keys.

The correctness condition for a set of rules is as follows. Infinite set, but their creates fields must not overlap. A rule is \textit{necessary} iff it is either mentioned by the input list, or is a dependency of a rule that satisfies the output list. The \textit{necessary} rules must be finite, and you can topologically sort their |creates|.

\subsection{Theory of Shake}
\label{sec:theory_shake}

Using the same terminology from the previous section, we can model our build tool as:

\begin{code}
data Rule =
    {creates :: Key
    ,rule :: Result
    }

data Result  =  Defer (List alpha Key) (List alpha Value -> Result)
             |  Result Value

shake :: RuleSet -> List alpha Key -> List alpha Value
shake rules xs = ellipses
\end{code}

The big enhancement is the introduction of dynamic dependencies. A rule can dynamically, based on the values of dependencies, add additional dependencies. We model dynamic dependencies with the |Result_alpha| type. You can think of this type as when run returns either a list of dependencies, and blocks until those dependencies are satisfied, or returns the resulting values.

\subsubsection{Correctness}

A system is correct if everything falls out. There must be a partial ordering on the |Key|'s, such that everything gets built in the right order. This property cannot be checked statically, since dependencies can be arbitrarily generated at runtime. A system is valid if it can be run to produce the outputs. If there is an ordering, the following algorithm will succeed.

Given a set of rules, and a set of keys, we define a number of terms:

\begin{itemize}
\item \textit{Interesting} rules are those which create something in the set of output keys, or who create something that an interesting rule has in it's Defer list.
\item \textit{Reduced} rules are those whose |rule| is in the |Result| state.
\item \textit{Reducible} rules are those which are in the |Defer| state, but whose immediate dependencies are all in the \textit{reduced} state.
\end{itemize}

Like in \make{}, the rules |creates| must all be distinct.

Given a set of rules, we are finished when all the \textit{interesting} rules are \textit{reduced}. We can proceed one step by taking a rule that is both \textit{interesting} and \textit{reducible} and running the deferred function on it. If there are no rules that are both \textit{interesting} and \textit{reducible} then we are stuck, and the build system has a logical inconsistency, either because there is no rule to build something, or the build rules form a cycle.

Note that we cannot know if the build system is consistent until it has completed. In particular, there are two ways for a build system to loop. Most obviously, an \textit{interesting} and \textit{reducible} rule could have a deferred action that never terminates. Alternatively, such a rule could immediately produce the same dependencies as previously, without making progress. We assume that each rule is structured in a way that there are a finite number of steps, and each step takes a finite amount of time (in practice, it is hard to write a rule that does not obey this property).

\section{Shake in Haskell}
\label{sec:user_view}

While our theory talks about |Key| and |Value|, our library is much more practically constrained. We have to add types on, model the relationship with types. We first present the interface to Shake, and the functions available. We do this by giving an example of code in Shake. After having defined what the concepts do, in the next section we explain how to implement these concepts.

\begin{figure}
\begin{code}
import Development.Shake
import System.FilePath

main = shake def $ do
    want ["Main"]

    "Main" *> exe -> do
        cs <- ls "*.c"
        let os = map (`replaceExtension` "o") cs
        need os
        system $ ["gcc","-o",exe] ++ os

    "*.o" *> \o -> do
        let c = replaceExtension o "c"
        need [c]
        headers <- cIncludes c
        need headers
        system ["gcc","-o",o,"-c",c]
\end{code}
\caption{Demo build system in Shake.}
\label{fig:demo}
\end{figure}

We give an example of a demo in Figure \ref{fig:demo}. Running this program will build |Main| from all the \file{*.c} files in the current directory. If we add or remove a \file{.c} file, or change any of the \file{.c} files or the header files they @#include@, then the necessary files will be recompiled.

The script produces (|want|'s) the file \file{Main}. To generate \file{Main} we take the directory listing of all \file{*.c} files (like the \prog{ls} command), change their extensions to \file{*.o}, require those files to be built (|need| them), then call \prog{gcc} to link them. To build any \file{*.o} file we take the associated \file{*.c}, make sure it's been built, then call the function |cIncludes| to get all headers transitively included. We require those headers, then we call \prog{gcc} to do the compilation.

This script demonstrates a number of features of Shake based build systems:

\begin{itemize}
\item It's a full Haskell library using main, while |main| can call |shake|, it can also do anything it likes, such as command line processing (see \S?).
\item The |ls| is tracked (see \S?), if the results of |ls| change, it will rebuild.
\item We run arbitrary system commands in the internals.
\item We fully track the dynamic dependencies with header files. The function |cIncludes| given a header file gets all the transitive @#include@ directives. (There is a better way of specifying the transitive closure, see \S?).
\end{itemize}

\subsection{Core Shake}

\begin{figure}
\begin{code}
data ShakeOptions = ShakeOptions
    {shakeDatabase :: FilePath
    ,shakeParallelism :: Int
    ,ellipses
    }
    deriving (Default)

data Rules a = Ellipses
    deriving (Monad, Monoid)

data Make a = Ellipses
    deriving (Monad, LiftIO)

runRules :: ShakeOptions -> Rules () -> IO ()

class (
    Show key, Typeable key, Eq key, Ord key, Hashable key, Binary key,
    Show value, Typeable value, Eq value, Ord value, Hashable value, Binary value
    ) => Rule key value where
    externalValue :: key -> IO (Maybe value)
    externalValue x = return Nothing

action :: Make a -> Rules ()

-- accumulate the Rule instances from defaultRule and rule, and put them in]
-- if no rules to build something then it's cache instance is dodgy anyway
defaultRule :: Rule key value => (key -> Maybe (Make value)) -> Rules ()

rule :: Rule key value => (key -> Maybe (Make value)) -> Rules ()

run :: Rule key value => List alpha key -> Make (List alpha value)
run1 :: Rule key value => key -> Make value

uncached :: Make ()
\end{code}
\caption{Primitive operations in Shake}
\label{fig:shake_core}
\end{figure}

The primitive interface to Shake is given in Figure \ref{fig:shake_core} -- everything else presented is defined in terms of these primitive interfaces.

A Shake build system is basically a set of rules. These rules are either rules exactly like the |Rule| type in \S\ref{sec:theory_shake} created with |rule|, or are instead simply |action| values. These are translated as adding an input value (uniquely created), along with a rule that generates it, which produces a |()| value. These rules are also matched specially so they cannot be cached.

We have used context synonyms to indicate that every |Key| or |Value| type must be in several type classes. We require:

\begin{description}
\item [Show] We require |Show| for debugging messages and logging.
\item [Typeable] We allow multiple rule/run types in one build system, to distinguish them we require a |Typeable| constraint.
\item [Eq] We require equality to match the values.
\item [Ord] We require ordering so that given a set of values we can pick a minimum, useful when we produce multiple files.
\item [Hashable] We require |Hashable| to accelerate searching.
\item [Binary] We require |Binary| so we can cache the values between runs, to achieve minimal rebuilds.
\end{description}

The |rule| declares a rule. Given a single |key| value, the rule returns |Nothing| to indicate that it cannot be called, or |Just| with the steps necessary to build the associated |value|. The function is used to encode infinite rules, as a rule could match potentially infinite numbers of |key|'s, but returns concrete rules in response to each one.

The |run| action looks for a matching |rule| with the same type. Since this involves runtime type matching, usually these rules are sugared up in type constrained versions. We take a list which allows parallelism, although you can imagine it just does a |mapM run1|.

We drive the code with the |shake| function, which takes an initial parameter of the options to control Shake. Typical options include which file to store the cached versions in (|shakeDatabase|), and the number of processors to use (|shakeParallelism|). These options are also used to select which mode to run Shake in, as described in \S\ref{sec:tools}.

Some functions should never be cached. As an example, functions that read from the file system in an untracked way -- such as getting the directory listing. Just because a previous run of the system detected that the directory contents was one way, we should recheck. The |uncached| function models this (the |uncached| function can be implemented in terms of |rule| and |run| by faking an incorrect instance definition, but by moving it into the core we get can optimise it to not store the cache, rather than simply storing and invaliding the cache).

The |Rule| class has two methods. One let's us associate a default rule. If no other rule matches we use this one. This allows us to use |newtype|'s to insert rules into the system.

We would like to move |defaultRule| into the type class |Rule|, but alas that breaks because of serialisation of existentials. See \S? for full details.

By keeping the core of Shake small, and defining lots of things on top, we keep it simple.

\subsubsection{Directory Listing}

\begin{code}
data Ls = Ls FilePath
instance Rule Ls [FilePath]

lsRule :: Rules ()
lsRule = defaultRule $ \(Ls x) ->
    uncached
    getDirectoryContents x

ls :: FilePath -> Make [FilePath]
ls = run1 . Ls
\end{code}

We make the function as |uncached|, because even if we have run |ls| the previous time, it may have changed. Another way of implementing this would be to take the SHA1 of the entire file system, and say it depends on that -- but that isn't practical. We rely on explicit type signatures to ensure that |Ls| is always used with the correct type.

\subsubsection{File Operations}

\begin{code}
newtype File = File FilePath
newtype Timestamp = Timestamp Int

instance Rule File TimeStamp where
    externalValue (File x) = do
        b <- doesFileExist x
        -- we always return |Just|, which is important
        if b then fmap Just getModificationTime else Just (-1)

fileRule :: Rules ()
fileRule = defaultRule \(File x) -> do
    b <- io $ doesFileExist x
    if b then io $ fmap TimeStamp getModificationTime else error "could not find file"


need :: [FilePath] -> Make ()
need xs = void (run $ map File xs :: Make [Timestamp])

want :: [FilePath] -> Rule ()
want xs = action $ need xs

(?>) :: (FilePath -> Bool) -> (FilePath -> Make ()) -> Rules ()
(?>) test act = rule $ \x -> if test x then Just act else Nothing

(*>) :: WildFilePath -> (FilePath -> Make ()) -> Rule ()
(*>) test act = (?= test) ?> act
\end{code}

We use Key/Value pairs, but in Make these are mainly restricted to keys being filenames, and Value's being their contents, which are left on disk. You could imagine storing a timestamp or SHA1 in the value instead. We found in practice that Timestamp is faster (noticably so for large files) and it's actually quite nice to do a \prog{touch} to cause something to be rebuilt!

We define |create| which is capable of describing all types of file related rule. It automatically gets the modification times from the resulting files. Next down the level of power is |(?>)|, which tests if a file matches a function and is suitable for any rules that create a single function. Finally, we have |(*>)| which just allows wildcards, and is much like the rule in \make{}. In practice, we have found that |create| is exceptionally rare, while |(?>)| is used about 25\% of the time, while |(*>)| is by far the most common. In simpler build systems we suspect |(*>)| would probably be all that is required.

\subsubsection{Operations}

We can layer on sugar like |readFileLines| quite easily. And also |readFile|, |system|, |mkdir|. In all cases, we try and emulate the \make{} behaviour of being more relaxed.

\begin{code}
readFile :: FilePath -> Make String
readFile x = do
    need x
    io $ Prelude.readFile x

system :: [String] -> Make ()
system xs = do
    x <- System.system $ unwords xs
    unless (x == ExitSuccess) $ error "Failed when running command"

mkdir :: FilePath -> Make ()
mkdir x = io $ createDirectoryRecursive True x
\end{code}

\subsubsection{Wrapping}

We can then defined:

\begin{code}
shake opts rules = runRules opts $ do
    fileRule
    lsRule
    rules
\end{code}

Note that if we had |defaultRule| in the type class, we could avoid having the |shake| wrapper.

\section{Implementing Shake}
\label{sec:developer_view}

We can implement Shake relatively easy. We don't give the entire implementation (for that, download the package from Hackage), but sketch some of the central ideas. When implementing Shake there are several goals:

\begin{description}
\item[Correctness] -- always rebuild enough, but we never rebuild something that could be reused.
\item[Efficiency] -- we try and make the implementation efficient.
\item[Parallelism] -- we try and do as much in parallel as possible.
\item[Error feedback] -- if the build system fails for some reason, such as the rules being incorrect as per \S\ref{sec:theory_shake}, then it's nice to give useful error messages. While this may sometimes conflict with efficiency (maintaining extra state to only be used in an error), it makes the system practical.
\end{description}

We first describe an implementation that is capable of building simple rules without parallelism of caching. We then add caching, and finally add parallelism.

Throughout this work, we assume that the build script does not change, merely the inputs. We make some allowances and checks for this case, but generally if you change the build script you should wipe the build.

\subsection{Dynamically Typed Values}
\label{sec:dynamically_typed}

Shake can work with multiple types of value in the rules. Storing heterogenous values in Haskell is problematic, so we define:

\begin{code}
data Any = Any (forall a . C a => a)
    deriving (Eq, Ord, Hashable, Binary)

type Key = Any
type Value = Any
\end{code}

This is a way of abstracting the |Key| and |Value| to store anything. For |Eq| and |Ord| and |Hashable| we just use the |TypeRep| and value as a pair, and apply the methods as that would be appropriate.

Defining the Binary instance is far harder. Serialising a value is easy, but deserialising a value is a nightmare -- we need to figure out the type of the value so we can find it's |Binary| instance. We solve this problem by building a table of all instances we know about which are referred to by |rule|. If there are no rules to build something it isn't useful, so we use that table to index in. Since storing the full type would require storing lots of types, we instead index them into a table and have a lookup table by index. While these concerns are fiddly and low-level, they can largely be ignored and we can assume all |Any| values have a good |Binary| instance. When deserialising, if we encounter a binary instance that we don't have a copy of, we just ignore the entire cache. This is pessimistic, but safe -- if the set of types has changed that implies the build system has changed, which is not tracked anyway (see \S\ref{sec:changing_makefile}).

\subsection{Basic Implementation}

Note that \make{} builds a graph, we can't do that. However, given the nature of the problem, we highly doubt that implementing \make{} by building a graph is the right approach! If we ignore parallelism and caching, we can build using a variable of the following type:

\begin{code}
type State = Map Key Result

data Result  =  Doing
             |  Done Value
             |  Also Key
\end{code}

At every point we have a global |State| value, initially starting with an empty |Map|. When we try and build an action we add it to the |State| as |Doing|. When we have built all it's dependencies, and run it, we add it to the |State| as |Done|. If while running the build system we encounter a |Doing|, then we have a cycle where a |Key| depends on itself.

When building a rule that has multiple outputs we always store it by the minimum |Key| value, which makes it consistent. Anything else that is done is put on the map with an |Also| pointing at the original key.

\subsection{Adding a Cache}
\label{sec:theory_shake_cache}

The standard behaviour for Shake is then to add a cache to get minimal rebuilding. Given a set of Key/Value pairs from last time, and a history trace.

We add code to save |Key|/|Value|, which is a pain with the existential, but possible.

Before running a rule, if we have something with an equal key

\begin{code}
data Val = Doing
    | Done Value [[Key]] Version Bool


data Status
    = Unchecked -- loaded from the cache without checking, should be checked before using (old version number)
    | Equal -- loaded from the cache, checked, and computed equal (keeps same version number)
    | Different -- either was not cached, or different from the cache (different version numbers)
\end{code}

When you compute something, if it existed and had the same version, and is identical, keep the same number. You are dirty if the version numbers of your keys do not match your version number. This allows multiple rebuilds to work properly. Also have a cache which means you and all your children have up to date versions. Do not save that boolean.

Version numbers let you load all the cache, validate and potentially rebuild some portion of the known universe, then save the cache back. As a result, some parts of the cache may have a much higher version than others, but you don't need to kill the rest until it gets broken. In any one run, a version number may only increase once at the same time as it gets its cached bit set to True.

Important point: if you run something, and it's dependencies are dirty, but it gave the same answer, you can still use that in the cache.



The reason for |[[Key]]| instead of just |[Key]| is so we figure out what can be checked in parallel.

For each Key/Value pair we also store the Key/Value list that was accessed during that run. We can do this quite effectively:

\begin{code}
-- Make sure key is in the cache, and has either has Equal or Different state.

ask :: Value ->

ask key =
    if Doing then error "has a loop"
    if Equal || Different then done
    if Unchecked then
        for each key
            ensures x
            if any are not equal then bail to Missing
    if Missing then
        run rule

ensures
\end{code}

rule = if has a value in the history, then need all the keys from last time. If they are all currently equal to their historic values then move from history to current. Work by maintaining two dictionaries

We also practically use a journal, so that hitting Ctrl+C doesn't break it. Do we need to remember if things are different/same when storing the cache?

\subsection{Parallelism}

Just add a lock in the Doing, use a thread pool and you are done. We always fork off all the rules in parallel, and modify the table atomically, but when checking equality we only fork threads if there is something to do (otherwise you end up with a lot of very small actions - since most just compare equalities).

\section{User Tools}
\label{sec:tools}

\subsection{Profiling}

\subsection{Analysis}

\subsection{Lint checking}

\subsection{Multiple Outputs}

Sometimes running one command will produce two outputs. As an example, running \prog{ghc} on \file{Foo.hs} produces both \file{Foo.o} and \file{Foo.hi}. Some things (things importing \file{Foo.hs}) require \file{Foo.hi}. Some things, say linking, require \file{Foo.o}. We can fake this because we know that a change in the \file{*.o} timestamp changes the \file{*.hi} timestamp, so we can write:

\begin{code}
"*.hi" *> \hi ->
    need [replaceExtension hi "o"]

"*.o" *> \o ->
    let hs = replaceExtension x "hs"
    need [hs] -- and it's dependencies, but let's ignore that for now
    system ["ghc","-c",hs]
\end{code}

Note that if we wrote it the other way, with the \file{*.o} depending on the \file{*.hi} then if the \file{*.hi} stayed the same we could end up screwed. We'd have written that neither file had changed, but both would have. Ouch. Also if we use SHA1 it's now not correct.

We can work around the problem by introducing a new type, |File2| which stores two files. We can then ask for both files at once, which computes them and stores both timestamps. Now to compute either we depend on the Both rule, and since that always changes when either does, we're safe.

\section{Evaluation}
\label{sec:evaluation}

We have used the resulting system extensively. It replaced a huge and error prone build system. Cite the 15\% study, and say we do very little.

\begin{code}

hasFlag :: String -> Bool

dotNet = do
    ruleAlways $ do
        res <- run1 $ Flag "DOTNETGEN"
        when res $
            addins <- run1 Addins
            need [dist $ x <.> "dll" | x <- addins]
\end{code}

\subsection{Multiple Results}

GHC produces a .hi and a .o file. You can think of the .o file as depending on the entire contents of the file, and the .hi depending on only the type signatures. A single GHC invocation needs to do all the work to do both, but often it won't change the .hi file if it doesn't need to. The multiple results captures this perfectly.

In most cases you can fake the dependency - i.e. say that Foo.o depends on both Foo.hs and Foo.hi - which may work, as whenever one gets built the other will be. However, consider a process that reads a file and splits it into the even numbers and the odd numbers, avoiding writing the file back if nothing has changed.

\subsection{Transitive Dependencies}

If you have a transitive dependency you can avoid it quite easily. Consider the problem of .c files

\subsection{Rules to Follow}

Do not use ls over a universe you are changing. If you ls, it should be in the source directory, not one you create - otherwise your build system as a result of generating a file could be unsatable. Ls should return the same at the start and end of the compilation.

Put all generated files somewhere entirely separate, such as dist or |_make|. Do not comingle them.

Make sure you normalise all filepaths, we recommend making them all relative to the root, never use combinations of @.@ and @/@ or @\\@.

\subsection{Lots of things generate .o files}

Then change them to have an extra extension, such as .hs.o.

\subsection{Command Line}

Just use actionAllow to filter which things they are allowed to need. You should be very careful not to miss out on things that they actually use, as you'll like get an error.


\section{Related Work}
\label{sec:related_work}

Build systems are an essential part of any large software project, yet often prove surprisingly tricky to get right. While most languages have a nice tool for building single language projects (ocamlbuild, ghc --make, Visual Studio projects), when building more complex multi-language projects, most people turn to \make{}. While there are many \make{} competitors (Scons, CMake, Ant), none have gained universal acceptance. We present Shake, a new build system based on a more powerful approach, which can do things \make{} cannot -- handling generated files properly. We have implemented Shake in Haskell, as a Haskell library, and it is used heavily -- compiling 10's of millions of lines of code per day.

A standard build system generates a dependency graph for all files, and processes them to meet the dependency constraints.


\section{Conclusions}
\label{sec:conclusions}

Shake is awesome. Any future work goes here.

\subsection*{Acknowledgements}

Thanks to Standard Chartered, where the software was developed. Thanks to Raphael Montelatici for the name Shake. Thanks to Evan Laforge for discussions, particularly about multiple files.


\bibliographystyle{plainnat}
\balance
\bibliography

\end{document}
