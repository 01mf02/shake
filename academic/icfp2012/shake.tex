\documentclass{sigplanconf}

% Email drafts to: M. George Hansen, Evan Laforge

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{balance}

\include{paper}
%include paper.fmt
%format (List (a) (b)) = "[" b "]_{" a "}"
%format Result_alpha = "\Varid{Result_\alpha}"
%format *> = "\mathbin{*\!\!\!>}"
%format ?> = "\mathbin{?\!\!\!>}"
%format ?= = "\mathbin{?\!\!\!=}"
%format `replaceExtension` = "\backtick{replaceExtension}"
%subst string a = "\!\text{\sf ``" a "\char34}\!"
%format context = "\Keyword{context}"


\newcommand{\file}{\textsf}
\newcommand{\prog}{\texttt}
\newcommand{\make}{\prog{make}}

\begin{document}
\conferenceinfo{ICFP'12,} {September 27--29, 2010, Baltimore, Maryland, USA.}
\CopyrightYear{2012}
\copyrightdata{978-1-60558-794-3/10/09}

\preprintfooter{}   % 'preprint' option specified.

\title{Shake -- A Better Make}
% \subtitle{}

\authorinfo{Neil Mitchell}
           {\verb"ndmitchell@gmail.com"}

\authorinfo{Max Bolingbroke}
           {\verb"ndmitchell@gmail.com"}

\maketitle

\begin{comment}
1. State the problem
2. Say why it’s an interesting problem
3. Say what your solution achieves
4. Say what follows from your solution
\end{comment}

\begin{abstract}
Build tools, such as \make{}, are typically used for compiling source code into executables. Unfortunately, most build tools fail to properly deal with generated source files, especially when the dependencies of those generated files can only be determined after the files have been generated. In many large software systems generated files are common, resulting in awkward hacks to paper over build tool inadequacies. We describe how to generalise build tools to deal properly with generated files. We have implemented our ideas as the Haskell library Shake, which has been used by Standard Chartered for the last three years as the basis for a complex build system involving millions of lines of code in many languages.
\end{abstract}

\category{D.3}{Software}{Programming Languages}

\terms
Languages

\keywords
build-system, compilation, Haskell

\section{Introduction}
\label{sec:introduction}

A build tool, such as \make{}, takes a set of input files, plus some rules, and produces some output files. Taking \make{} as an example, a build rule looks like:

\begin{code}
{-"\textsf{result.tar : a.txt b.txt}"-}
    {-"\textsf{tar -cf result.tar a.txt b.txt}"-}
\end{code}

\noindent This rule builds the tar archive \file{result.tar} from the inputs \file{a.txt} and \file{b.txt}. Whenever \file{a.txt} or \file{b.txt} changes \file{result.tar} will be regenerated.

What if we want to build \file{result.tar} from the list of files in \file{list.txt}? \make{} offers no easy way to express this pattern (there are workarounds, discussed in \S\ref{sec:make_hacks}, but none are pleasant or effective). However, using the build tool we develop in this paper, we can write:

\begin{code}
"result.tar" *> \_ -> do
    need ["list.txt"]
    contents <- liftM lines $ readFile "list.txt"
    need contents
    system $ ["tar","-cf","result.tar"] ++ contents
\end{code}

This rule describes how to build \file{result.tar}. We depend on (|need|) the file \file{list.txt}. We read \file{list.txt}, and store each line in |contents| -- which is a list of the files that should go into \file{result.tar}. Next, we depend on all the files in |contents|, and finally call the \prog{tar} program specifying the files in |contents|. If \file{list.txt} changes, or any of the files listed by \file{list.txt} change, then \file{result.tar} will be rebuilt.

The key difference from \make{} (and nearly all other build tools) is that rather than specifying the dependencies of a rule \textit{in advance}, we allow further dependencies to be specified \textit{after} using previous dependencies. This difference is crucial to properly handle generated files.

We have implemented our build tool as a Haskell library, named Shake, which is available online\footnote{\url{http://hackage.haskell.org/package/shake}}. Shake properly handles generated files and includes the important features of \make{}, such as minimal rebuilds (running only a subset of the rules when some subset of the inputs change), and parallelising the build (running multiple independent rules at the same time). By implementing Shake as a Haskell library we allow rules to be written using the full power of Haskell, including the use of modules and functions to properly structure large systems.

\subsection{Contributions}

\begin{itemize}
\item We describe the theory underlying \make{} (\S\ref{sec:theory_make}), and how to revise this theory to properly handle generated files (\S\ref{sec:theory_shake}).
\item We describe how to extend our theory with a cache, to enable minimal rebuilds (\S\ref{sec:theory_shake_cache}).
\item We describe how to implement our build tool in Haskell, including how to present the underlying theory in a way that is practically usable (\S\ref{sec:user_view}), and how to implement it efficiently (\S\ref{sec:developer_view}). While Haskell is not essential to implement our build tool, it offers a number of advantages -- primarily making IO effects explicit and providing nice syntactic sugar.
\item We describe how additional features can be added to our build tool, including a Lint tool (\S?), a profiling tool (\S?) and a dependency analysis tool (\S?).
\item We allow rule dependencies and targets to be arbitrary values. While we can represent files (\S?), we are also able to represent static configuration information (\S?), the list of files in a directory (\S?) and commands that produce multiple results (\S?).
\item We have implemented a large build system using Shake (\S?). The build system is 9000 of lines of Haskell, building over a million lines of source code and over a million lines of generated code, written in many programming languages. We originally implemented this build system using \make{}, but the result was slow to run, hard to maintain, and frequently caused spurious compile failures. Since using Shake, our build system has ceased to be a problem.
\item We give a number of guidelines to follow when using Shake, based on our experiences (\S?).
\end{itemize}


\section{Theory}
\label{sec:theory}

In this section we first describe the underlying basis of \make{}, then the underlying basis of our build system. Finally, we describe how to support minimal rebuilds in Shake. In \S\ref{sec:user_view} we show how we can implement these ideas in a library.

\subsection{Theory of Make}
\label{sec:theory_make}

While the \make{} tool is heavily file based, this is not an essential property of the ideas behind \make{}. We use the type |Key| for things that can be results or dependencies (i.e. file names) and the type |Value| for the value associated with a |Key| (i.e.  file contents). Using this abstraction, we can model \make{} as:

\begin{code}
data Rule =
    {depends :: List alpha Key
    ,creates :: Key
    ,action :: List alpha Value -> Value
    }

make :: Set Rule -> Key -> Value
\end{code}

The |make| function takes a (possibly infinite) set of rules, the target |Key| to build, and returns the |Value| associated with that |Key|. A rule can be modelled as the |Key|s it |depends| on, the |Key| it |creates|, and the |action| that takes the depended upon |Value|s and produces the result |Value|. We use |List alpha bullet| to denote a list which must have length |alpha|, requiring that the |depends| list and the list passed to |action| are equal in length. We say a |Rule| is associated with a |Key| if it has that |Key| as its |creates| field.

While \make{} allows specifying multiple targets (i.e. a list of |Key|s to build), we can encode multiple targets by creating a distinguished rule that depends on all the targets and whose action returns all their values, and then require building just that rule.

For a call to |make| to be valid, given a set of rules named |rs| and a |Key| named |target|, we require:

\begin{description}
\item [No duplicate rules] No |Key| may have two associated rules.
\item [No missing rules] Every item in a |depends| must have an associated rule.
\item [Root rule] There must be a rule associated with the target.
\item [Finite] There must be a finite number of rules reachable from the target following the |depends| field to the associated rules.
\item [Acyclic] No key may be created by a rule, and also in either it's dependencies, or it's childrens dependencies etc.
\end{description}

Such a list can be easily computed. There are many such lists, and in fact the minimum structure is a graph, which is how \make{} actually works. The graph allows for more parallelism.

\subsection{Theory of Shake}
\label{sec:theory_shake}

Using the same terminology from the previous section, we can model our build tool as:

\begin{code}
data Rule =
    {creates :: Key
    ,rule :: Result
    }

data Result  =  Defer Key (Value -> Result)
             |  Result Value

shake :: RuleSet -> Key -> Value
shake rules xs = ellipses
\end{code}

The big enhancement is the introduction of dynamic dependencies. A rule can dynamically, based on the values of dependencies, add additional dependencies. We model dynamic dependencies with the |Result_alpha| type. You can think of this type as when run returns either a list of dependencies, and blocks until those dependencies are satisfied, or returns the resulting values.

\subsubsection{Correctness}

A system is correct if everything falls out. There must be a partial ordering on the |Key|'s, such that everything gets built in the right order. This property cannot be checked statically, since dependencies can be arbitrarily generated at runtime. A system is valid if it can be run to produce the outputs. If there is an ordering, the following algorithm will succeed.

\begin{itemize}
\item \textit{Result} rules are those whose |rule| is in the |Result| state.
\item \textit{Reducible} rules are those which are not \textit{results}, but whose immediate dependencies are all \textit{results}.
\item \textit{Required} rules are those which are not \textit{results}, but which create something in the set of output keys, or who create something that a \textit{required} rule has in it's |Defer| list. We can guarantee that all \textit{required} rules must be evaluated for the build system to finish.
\end{itemize}

Like in \make{}, the rules |creates| must all be distinct.

Given a set of rules, we are finished when all the \textit{required} rules are \textit{results}. We can proceed one step by taking a rule that is both \textit{required} and \textit{reducible} and running the deferred function on it (\textit{reducing} it). If there are no rules that are both \textit{required} and \textit{reducible} then we are stuck, and the build system has a logical inconsistency, either because there is no rule to build something, or the build rules form a cycle.

Note that we cannot know if the build system is consistent until it has completed. In particular, there are two ways for a build system to loop. Most obviously, an \textit{required} and \textit{reducible} rule could have a deferred action that never terminates. Alternatively, such a rule could immediately produce the same dependencies as previously, without making progress. We assume that each rule is structured in a way that there are a finite number of steps, and each step takes a finite amount of time (in practice, it is hard to write a rule that does not obey this property).

\subsection{Cached Shake}
\label{sec:theory_cached}

\make{} does something really easy - it just looks at the rules and uses an ordering on the values. We don't want to do an ordering on the value (just because you modify a dependent file, doesn't mean it doesn't need rebuilding). We therefore imagine we have run a Shake execution, and recorded everything that happened. In particular, we have:

\begin{code}
type History = Map Key ([(Key, Value)], Value)
\end{code}

This says that last time round |Key| depended on the values |[(Key, Value)]| -- so what it depended on and what those things were equal to, and produced the second component |Value|.

We can use this cache to optimise. If a rule has never been \textit{reduced}, and all it's previous dependents are \textit{results}, and they all the the identical values to last time, we can skip running the rule and immediately reduce it to it's previous value. In order to get minimal rebuilding we would have to prefer reducing with the cache in all circumstances.

The key thing is that things in our cache are duplicated in the environment. For example, if we are recording time stamps of files, then the real file may now have a different timestamp. Therefore, we also must check that the value of the thing on disk is consistent. When reading the timestamp of an on-disk file, there three state -- it has a value, which can be determined, it lacks a value because it does not exist or is missing (the thing should be rebuild), it never exists and thus lacks a value and is unapplicable (the thing should never be rebuilt). If the value has changed, or is missing, then we don't use the cache, but rerun the rule.


\section{Shake in Haskell}
\label{sec:user_view}

While our theory talks about |Key| and |Value|, our library is much more practically constrained. We have to add types on, model the relationship with types. We first present the interface to Shake, and the functions available. We do this by giving an example of code in Shake. After having defined what the concepts do, in the next section we explain how to implement these concepts.

\begin{figure}
\begin{code}
import Development.Shake
import System.FilePath

main = shake def $ do
    want ["Main"]

    "Main" *> exe -> do
        cs <- ls "*.c"
        let os = map (`replaceExtension` "o") cs
        need os
        system $ ["gcc","-o",exe] ++ os

    "*.o" *> \o -> do
        let c = replaceExtension o "c"
        need [c]
        headers <- cIncludes c
        need headers
        system ["gcc","-o",o,"-c",c]
\end{code}
\caption{Demo build system in Shake.}
\label{fig:demo}
\end{figure}

We give an example of a demo in Figure \ref{fig:demo}. Running this program will build |Main| from all the \file{*.c} files in the current directory. If we add or remove a \file{.c} file, or change any of the \file{.c} files or the header files they @#include@, then the necessary files will be recompiled.

The script produces (|want|'s) the file \file{Main}. To generate \file{Main} we take the directory listing of all \file{*.c} files (like the \prog{ls} command), change their extensions to \file{*.o}, require those files to be built (|need| them), then call \prog{gcc} to link them. To build any \file{*.o} file we take the associated \file{*.c}, make sure it's been built, then call the function |cIncludes| to get all headers transitively included. We require those headers, then we call \prog{gcc} to do the compilation.

This script demonstrates a number of features of Shake based build systems:

\begin{itemize}
\item It's a full Haskell library using main, while |main| can call |shake|, it can also do anything it likes, such as command line processing (see \S?).
\item The |ls| is tracked (see \S?), if the results of |ls| change, it will rebuild.
\item We run arbitrary system commands in the internals.
\item We fully track the dynamic dependencies with header files. The function |cIncludes| given a header file gets all the transitive @#include@ directives. (There is a better way of specifying the transitive closure, see \S?).
\end{itemize}

\subsection{Core Shake}

\begin{figure}
\begin{code}
data ShakeOptions = ShakeOptions
    {shakeDatabase :: FilePath
    ,shakeParallelism :: Int
    ,ellipses
    }
    deriving (Default)

data Rules a = Ellipses
    deriving (Monad, Monoid)

data Make a = Ellipses
    deriving (Monad, LiftIO)

run :: ShakeOptions -> Rules () -> IO ()

class (
    Show key, Typeable key, Eq key, Ord key, Hashable key, Binary key,
    Show value, Typeable value, Eq value, Ord value, Hashable value, Binary value
    ) => Rule key value where
    externalValue :: key -> IO (Maybe value)
    externalValue x = return Nothing

action :: Make a -> Rules ()

-- accumulate the Rule instances from defaultRule and rule, and put them in]
-- if no rules to build something then it's cache instance is dodgy anyway
defaultRule :: Rule key value => (key -> Maybe (Make value)) -> Rules ()

rule :: Rule key value => (key -> Maybe (Make value)) -> Rules ()

apply :: Rule key value => List alpha key -> Make (List alpha value)
apply1 :: Rule key value => key -> Make value
\end{code}
\caption{Primitive operations in Shake}
\label{fig:shake_core}
\end{figure}

The primitive interface to Shake is given in Figure \ref{fig:shake_core} -- everything else presented is defined in terms of these primitive interfaces.

A Shake build system is basically a set of rules. These rules are either rules exactly like the |Rule| type in \S\ref{sec:theory_shake} created with |rule|, or are instead simply |action| values. These are translated as adding an input value (uniquely created), along with a rule that generates it, which produces a |()| value. These rules are also matched specially so they cannot be cached.

We have used context synonyms to indicate that every |Key| or |Value| type must be in several type classes. We require:

\begin{description}
\item [Show] We require |Show| for debugging messages and logging.
\item [Typeable] We allow multiple rule/run types in one build system, to distinguish them we require a |Typeable| constraint.
\item [Eq] We require equality to match the values.
\item [Ord] We require ordering so that given a set of values we can pick a minimum, useful when we produce multiple files.
\item [Hashable] We require |Hashable| to accelerate searching.
\item [Binary] We require |Binary| so we can cache the values between runs, to achieve minimal rebuilds.
\end{description}

The |rule| declares a rule. Given a single |key| value, the rule returns |Nothing| to indicate that it cannot be called, or |Just| with the steps necessary to build the associated |value|. The function is used to encode infinite rules, as a rule could match potentially infinite numbers of |key|'s, but returns concrete rules in response to each one.

The |run| action looks for a matching |rule| with the same type. Since this involves runtime type matching, usually these rules are sugared up in type constrained versions. We take a list which allows parallelism, although you can imagine it just does a |mapM run1|.

We drive the code with the |shake| function, which takes an initial parameter of the options to control Shake. Typical options include which file to store the cached versions in (|shakeDatabase|), and the number of processors to use (|shakeParallelism|). These options are also used to select which mode to run Shake in, as described in \S\ref{sec:tools}.

The |Rule| class has two methods. One let's us associate a default rule. If no other rule matches we use this one. This allows us to use |newtype|'s to insert rules into the system.

We would like to move |defaultRule| into the type class |Rule|, but alas that breaks because of serialisation of existentials. See \S? for full details.

By keeping the core of Shake small, and defining lots of things on top, we keep it simple.

\subsubsection{Directory Listing}

\begin{code}
data Ls = Ls FilePath
instance Rule Ls [FilePath] where
    externalValue (Ls x) = fmap Just $ getDirectoryContents x

lsRule :: Rules ()
lsRule = rule $ \(Ls x) -> liftIO $ getDirectoryContents x

ls :: FilePath -> Make [FilePath]
ls = run1 . Ls
\end{code}

We make the function as |uncached|, because even if we have run |ls| the previous time, it may have changed. Another way of implementing this would be to take the SHA1 of the entire file system, and say it depends on that -- but that isn't practical. We rely on explicit type signatures to ensure that |Ls| is always used with the correct type.

\subsubsection{File Operations}

\begin{code}
newtype File = File FilePath
newtype Timestamp = Timestamp Int

instance Rule File TimeStamp where
    externalValue (File x) = do
        b <- doesFileExist x
        -- we always return |Just|, which is important
        if b then fmap Just getModificationTime else Just (-1)

fileRule :: Rules ()
fileRule = defaultRule \(File x) -> do
    b <- io $ doesFileExist x
    if b then io $ fmap TimeStamp getModificationTime else error "could not find file"


need :: [FilePath] -> Make ()
need xs = void (run $ map File xs :: Make [Timestamp])

want :: [FilePath] -> Rule ()
want xs = action $ need xs

(?>) :: (FilePath -> Bool) -> (FilePath -> Make ()) -> Rules ()
(?>) test act = rule $ \x -> if test x then Just act else Nothing

(*>) :: WildFilePath -> (FilePath -> Make ()) -> Rule ()
(*>) test act = (?= test) ?> act
\end{code}

We use Key/Value pairs, but in Make these are mainly restricted to keys being filenames, and Value's being their contents, which are left on disk. You could imagine storing a timestamp or SHA1 in the value instead. We found in practice that Timestamp is faster (noticably so for large files) and it's actually quite nice to do a \prog{touch} to cause something to be rebuilt!

We define |create| which is capable of describing all types of file related rule. It automatically gets the modification times from the resulting files. Next down the level of power is |(?>)|, which tests if a file matches a function and is suitable for any rules that create a single function. Finally, we have |(*>)| which just allows wildcards, and is much like the rule in \make{}. In practice, we have found that |create| is exceptionally rare, while |(?>)| is used about 25\% of the time, while |(*>)| is by far the most common. In simpler build systems we suspect |(*>)| would probably be all that is required.

\subsubsection{Operations}

We can layer on sugar like |readFileLines| quite easily. And also |readFile|, |system|, |mkdir|. In all cases, we try and emulate the \make{} behaviour of being more relaxed.

\begin{code}
readFile :: FilePath -> Make String
readFile x = do
    need x
    io $ Prelude.readFile x

system :: [String] -> Make ()
system xs = do
    x <- System.system $ unwords xs
    unless (x == ExitSuccess) $ error "Failed when running command"

mkdir :: FilePath -> Make ()
mkdir x = io $ createDirectoryRecursive True x
\end{code}

\subsubsection{Wrapping}

We can then defined:

\begin{code}
shake opts rules = runRules opts $ do
    fileRule
    lsRule
    rules
\end{code}

Note that if we had |defaultRule| in the type class, we could avoid having the |shake| wrapper.

\section{Implementing Shake}
\label{sec:developer_view}

We can implement Shake relatively easy. We don't give the entire implementation (for that, download the package from Hackage), but sketch some of the central ideas. When implementing Shake there are several goals:

\begin{description}
\item[Correctness] -- always rebuild enough, but we never rebuild something that could be reused.
\item[Efficiency] -- we try and make the implementation efficient.
\item[Parallelism] -- we try and do as much in parallel as possible.
\item[Error feedback] -- if the build system fails for some reason, such as the rules being incorrect as per \S\ref{sec:theory_shake}, then it's nice to give useful error messages. While this may sometimes conflict with efficiency (maintaining extra state to only be used in an error), it makes the system practical.
\end{description}

We first describe an implementation that is capable of building simple rules without parallelism of caching. We then add caching, and finally add parallelism.

Throughout this work, we assume that the build script does not change, merely the inputs. We make some allowances and checks for this case, but generally if you change the build script you should wipe the build.

\subsection{Dynamically Typed Values}
\label{sec:dynamically_typed}

Shake can work with multiple types of value in the rules. Storing heterogenous values in Haskell is problematic, so we define:

\begin{code}
data Any = Any (forall a . C a => a)
    deriving (Eq, Ord, Hashable, Binary)

type Key = Any
type Value = Any
\end{code}

This is a way of abstracting the |Key| and |Value| to store anything. For |Eq| and |Ord| and |Hashable| we just use the |TypeRep| and value as a pair, and apply the methods as that would be appropriate.

Defining the Binary instance is far harder. Serialising a value is easy, but deserialising a value is a nightmare -- we need to figure out the type of the value so we can find it's |Binary| instance. We solve this problem by building a table of all instances we know about which are referred to by |rule|. If there are no rules to build something it isn't useful, so we use that table to index in. Since storing the full type would require storing lots of types, we instead index them into a table and have a lookup table by index. While these concerns are fiddly and low-level, they can largely be ignored and we can assume all |Any| values have a good |Binary| instance. When deserialising, if we encounter a binary instance that we don't have a copy of, we just ignore the entire cache. This is pessimistic, but safe -- if the set of types has changed that implies the build system has changed, which is not tracked anyway (see \S\ref{sec:changing_makefile}).

\subsection{Basic Implementation}

Note that \make{} builds a graph, we can't do that. However, given the nature of the problem, we highly doubt that implementing \make{} by building a graph is the right approach! If we ignore parallelism and caching, we can build using a variable of the following type:

\begin{code}
type State = Map Key Result

data Result  =  Doing
             |  Done Value
             |  Also Key
\end{code}

At every point we have a global |State| value, initially starting with an empty |Map|. When we try and build an action we add it to the |State| as |Doing|. When we have built all it's dependencies, and run it, we add it to the |State| as |Done|. If while running the build system we encounter a |Doing|, then we have a cycle where a |Key| depends on itself.

When building a rule that has multiple outputs we always store it by the minimum |Key| value, which makes it consistent. Anything else that is done is put on the map with an |Also| pointing at the original key.

\subsection{Adding a Cache}
\label{sec:theory_shake_cache}

The standard behaviour for Shake is then to add a cache to get minimal rebuilding. Given a set of Key/Value pairs from last time, and a history trace.

We add code to save |Key|/|Value|, which is a pain with the existential, but possible.

Before running a rule, if we have something with an equal key

\begin{code}
data Val = Doing
    | Done Value [[Key]] Version Bool


data Status
    = Unchecked -- loaded from the cache without checking, should be checked before using (old version number)
    | Equal -- loaded from the cache, checked, and computed equal (keeps same version number)
    | Different -- either was not cached, or different from the cache (different version numbers)
\end{code}

When you compute something, if it existed and had the same version, and is identical, keep the same number. You are dirty if the version numbers of your keys do not match your version number. This allows multiple rebuilds to work properly. Also have a cache which means you and all your children have up to date versions. Do not save that boolean.

Version numbers let you load all the cache, validate and potentially rebuild some portion of the known universe, then save the cache back. As a result, some parts of the cache may have a much higher version than others, but you don't need to kill the rest until it gets broken. In any one run, a version number may only increase once at the same time as it gets its cached bit set to True.

Important point: if you run something, and it's dependencies are dirty, but it gave the same answer, you can still use that in the cache.



The reason for |[[Key]]| instead of just |[Key]| is so we figure out what can be checked in parallel.

For each Key/Value pair we also store the Key/Value list that was accessed during that run. We can do this quite effectively:

\begin{code}
-- Make sure key is in the cache, and has either has Equal or Different state.

ask :: Value ->

ask key =
    if Doing then error "has a loop"
    if Equal || Different then done
    if Unchecked then
        for each key
            ensures x
            if any are not equal then bail to Missing
    if Missing then
        run rule

ensures
\end{code}

rule = if has a value in the history, then need all the keys from last time. If they are all currently equal to their historic values then move from history to current. Work by maintaining two dictionaries

We also practically use a journal, so that hitting Ctrl+C doesn't break it. Do we need to remember if things are different/same when storing the cache?

\subsection{Parallelism}

Just add a lock in the Doing, use a thread pool and you are done. We always fork off all the rules in parallel, and modify the table atomically, but when checking equality we only fork threads if there is something to do (otherwise you end up with a lot of very small actions - since most just compare equalities).

\section{User Tools}
\label{sec:tools}

\subsection{Profiling}

\subsection{Analysis}

\subsection{Lint checking}

\subsection{Multiple Outputs}

Sometimes running one command will produce two outputs. As an example, running \prog{ghc} on \file{Foo.hs} produces both \file{Foo.o} and \file{Foo.hi}. Some things (things importing \file{Foo.hs}) require \file{Foo.hi}. Some things, say linking, require \file{Foo.o}. We can fake this because we know that a change in the \file{*.o} timestamp changes the \file{*.hi} timestamp, so we can write:

\begin{code}
"*.hi" *> \hi ->
    need [replaceExtension hi "o"]

"*.o" *> \o ->
    let hs = replaceExtension x "hs"
    need [hs] -- and it's dependencies, but let's ignore that for now
    system ["ghc","-c",hs]
\end{code}

Note that if we wrote it the other way, with the \file{*.o} depending on the \file{*.hi} then if the \file{*.hi} stayed the same we could end up screwed. We'd have written that neither file had changed, but both would have. Ouch. Also if we use SHA1 it's now not correct.

We can work around the problem by introducing a new type, |File2| which stores two files. We can then ask for both files at once, which computes them and stores both timestamps. Now to compute either we depend on the Both rule, and since that always changes when either does, we're safe.

\section{Evaluation}
\label{sec:evaluation}

We have used the resulting system extensively. It replaced a huge and error prone build system. Cite the 15\% study, and say we do very little.

\begin{code}

hasFlag :: String -> Bool

dotNet = do
    ruleAlways $ do
        res <- run1 $ Flag "DOTNETGEN"
        when res $
            addins <- run1 Addins
            need [dist $ x <.> "dll" | x <- addins]
\end{code}

\subsection{Multiple Results}

GHC produces a .hi and a .o file. You can think of the .o file as depending on the entire contents of the file, and the .hi depending on only the type signatures. A single GHC invocation needs to do all the work to do both, but often it won't change the .hi file if it doesn't need to. The multiple results captures this perfectly.

In most cases you can fake the dependency - i.e. say that Foo.o depends on both Foo.hs and Foo.hi - which may work, as whenever one gets built the other will be. However, consider a process that reads a file and splits it into the even numbers and the odd numbers, avoiding writing the file back if nothing has changed.

\subsection{Transitive Dependencies}

If you have a transitive dependency you can avoid it quite easily. Consider the problem of .c files

\subsection{Rules to Follow}

Do not use ls over a universe you are changing. If you ls, it should be in the source directory, not one you create - otherwise your build system as a result of generating a file could be unsatable. Ls should return the same at the start and end of the compilation.

Put all generated files somewhere entirely separate, such as dist or |_make|. Do not comingle them.

Make sure you normalise all filepaths, we recommend making them all relative to the root, never use combinations of @.@ and @/@ or @\\@.

\subsection{Lots of things generate .o files}

Then change them to have an extra extension, such as .hs.o.

\subsection{Command Line}

Just use actionAllow to filter which things they are allowed to need. You should be very careful not to miss out on things that they actually use, as you'll like get an error.


\section{Related Work}
\label{sec:related_work}

Build systems are an essential part of any large software project, yet often prove surprisingly tricky to get right. While most languages have a nice tool for building single language projects (ocamlbuild, ghc --make, Visual Studio projects), when building more complex multi-language projects, most people turn to \make{}. While there are many \make{} competitors (Scons, CMake, Ant), none have gained universal acceptance. We present Shake, a new build system based on a more powerful approach, which can do things \make{} cannot -- handling generated files properly. We have implemented Shake in Haskell, as a Haskell library, and it is used heavily -- compiling 10's of millions of lines of code per day.

A standard build system generates a dependency graph for all files, and processes them to meet the dependency constraints.


\section{Conclusions}
\label{sec:conclusions}

Shake is awesome. Any future work goes here.

\subsection*{Acknowledgements}

Thanks to Standard Chartered, where the software was developed. Thanks to Raphael Montelatici for the name Shake. Thanks to Evan Laforge for discussions, particularly about multiple files.


\bibliographystyle{plainnat}
\balance
\bibliography

\end{document}
